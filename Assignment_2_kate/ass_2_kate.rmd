## Lab assignment 2: Social network analysis and modeling

```{r}
library('igraph')
library('network')
library('intergraph')
#comments
```

Type any R code in the chunk, for example:
```{r}
#read data from the folder data
highschool_edge<-read.csv("Human_networks/Assignment_2_kate/data/Highschool_network_edge.csv")
highschool_att <- read.csv("Human_networks/Assignment_2_kate/data/Highschool_network_att.csv")
facebook_att <- read.csv("Human_networks/Assignment_2_kate/data/Facebook_network_att.csv")
facebook_edge <- read.csv("Human_networks/Assignment_2_kate/data/Facebook_network_edge.csv")
#check that it works!
```
```{r}
highschool_att
```

```{r}
#build high school network
highschool_nodes<-data.frame(name=as.character(highschool_att$NodeID),
                  gender=as.character(highschool_att$Gender),
                  hall=as.character(highschool_att$Hall))
highschool_edges<-data.frame(from=c(as.character(highschool_edge[,1])),
                  to=c(as.character(highschool_edge[,2])))
Highschool<-graph_from_data_frame(highschool_edges,directed = FALSE,vertices = highschool_nodes)
co <- components(Highschool)
Highschool <- induced.subgraph(Highschool, which(co$membership == which.max(co$csize))) #use only the largest component for analysis
summary(Highschool)

#build facebook network
facebook_nodes<-data.frame(name=as.character(facebook_att$NodeID))
facebook_edges<-data.frame(from=c(as.character(facebook_edge[,1])),
                           to=c(as.character(facebook_edge[,2])))
Facebook<-graph_from_data_frame(facebook_edges,directed = FALSE,vertices = facebook_nodes)
summary(Facebook)
```


```{r}

#function to visualize the network (with interaction)
library(visNetwork)
set.seed(100)
Highschool_interactive_layout<-visNetwork(data.frame(id=V(Highschool)$name), highschool_edges, main = "Highschool",submain="Can zoom in/out to check the IDs and ties") %>%
  visIgraphLayout(layout = "layout_nicely",smooth =  FALSE) %>%
  visNodes(shape="circle",label = TRUE) %>%
  visOptions(highlightNearest = list(enabled = T, hover = T), nodesIdSelection = T)

Highschool_interactive_layout

```
```{r}

# find the node of he hisghest degree
#degree(Highschool)
which.max(degree(Highschool))
V(Highschool)[which.max(degree(Highschool))]

```
```{r}
#find the node of the highest betweenness centrality
#
which.max(betweenness(Highschool))
V(Highschool)[which.max(betweenness(Highschool))]

```
```{r}
#find the node of the highest closeness centrality
#closeness(Highschool)
which.max(closeness(Highschool))
V(Highschool)[which.max(closeness(Highschool))]

```
```{r}
#find the node with the highest eigen
eigen_centrality(Highschool)
V(Highschool)[which.max(eigen_centrality(Highschool))] #110
#
# #the highest degree node is 110
#
# #find the maximum in data frame
# max(eigen_centrality(Highschool))
```


Question 2 (5 points):
•	Study the correlations between a) degree and betweenness, b) degree and closeness, c) degree and eigenvector for all the nodes in the Highschool network;
•	Study the correlations between a) degree and betweenness, b) degree and closeness, c) degree and eigenvector for all the nodes in the Facebook network;
•	From the above results, how well do different metrics correlate with each other? Which centrality metric will you use and why?
Please provide more than just a correlation coefficient to answer Question 2. You are suggested to study the correlations by developing a scatter plot as below, in which every dot represents a node in the network, with xlab as degree and ylab as closeness.
```{r}
#check the correlation between degree and betweenness
cor.test(degree(Highschool),betweenness(Highschool))
```
```{r}
#check the correlation between degree and closeness
cor.test(degree(Highschool),closeness(Highschool))
```
```{r}
#check the correlation between degree and eigenvector
eigen_hs <- eigen_centrality(Highschool)$vector
cor.test(degree(Highschool),eigen_hs)
```
```{r}
#check the correlation between degree and betweenness
cor.test(degree(Facebook),betweenness(Facebook))
```
```{r}
#check the correlation between degree and closeness
cor.test(degree(Facebook),closeness(Facebook))
```
```{r}
#check the correlation between degree and eigenvector and add the trand line
eigen_fb <- eigen_centrality(Facebook)$vector
cor.test(degree(Facebook),eigen_fb)
```
```{r}
# cor.test(degree(Facebook),eigen_centrality(Facebook))
#add the trand line to the plot
# abline(lm(degree(Highschool)~betweenness(Highschool)),col="red")

#make a scatter plot for degree and closeness and add the trand line
plot(degree(Highschool),closeness(Highschool),xlab="Degree",ylab="Closeness")
abline(lm(closeness(Highschool)~degree(Highschool)),col="red")
#make the confident interval for the trand line with grey color
```



```{r}
#make a scatter plot for degree and closeness for Facebook
plot(degree(Highschool),betweenness(Highschool),xlab="Degree",ylab="Closeness")
abline(lm(closeness(Highschool)~degree(Highschool)),col="red")
```
```{r}
#make a scatter plot for degree and closeness for Facebook
plot(degree(Facebook),closeness(Facebook),xlab="degree",ylab="closeness")
abline(lm(closeness(Facebook)~degree(Facebook)),col="red")
```
```{r}
# calculate the shortest path lengths between every pair of two nodes in Highschool network

distances(
  Highschool,
  v = V(Highschool),
  to = V(Highschool),
  mode = c("all", "out", "in"),
  weights = NULL) #Shortest path lengths between every pair of two nodes in the network

```
```{r}
#make a histogram of the shortest path lengths between every pair of two nodes in Highschool network with percentiles
hist(distances(Highschool),xlab="shortest path length",ylab="% of total cout by group",main="Histogram of the shortest path lengths between every pair of two nodes in Highschool network",breaks=10,prob=T)
#add percentiles and add the value of the percentiles to the plot
abline(v=quantile(distances(Highschool),c(0.25,0.5,0.75)),col="red")
text(quantile(distances(Highschool),c(0.25,0.5,0.75)),c(0.1,0.1,0.1),labels=quantile(distances(Highschool),c(0.25,0.5,0.75)),col="red")
```
```{r}
hist(distances(Facebook),xlab="shortest path length",ylab="% of total cout by group",main="Histogram of the shortest path lengths between every pair of two nodes in Facebook network",breaks=10,prob=T)
#add percentiles and add the value of the percentiles to the plot
abline(v=quantile(distances(Facebook),c(0.25,0.5,0.75)),col="red")
text(quantile(distances(Facebook),c(0.25,0.5,0.75)),c(0.1,0.1,0.1),labels=quantile(distances(Facebook),c(0.25,0.5,0.75)),col="red")
```


Test the above hypothesis by the following steps (Question 4, 4 points):
```{r}
#visualize the Highschool network by gender
library(RColorBrewer)
coul  <- brewer.pal(length(unique( V(Highschool)$gender)), "Set2")
my_color <- coul[as.numeric(as.factor(V(Highschool)$gender))]
set.seed(10)
plot(Highschool, vertex.color = my_color,
     vertex.size=5,
     layout=layout.fruchterman.reingold(Highschool),vertex.label=NA,
     main="Highschool network by gender")
#add the legend of the color of the nodes at the top left corner
legend("bottomleft", legend=levels(as.factor(V(Highschool)$gender)) ,col = coul , bty = "n", pch=200 , pt.cex = 1.5, cex = 1.5, horiz = FALSE, inset = c(0.1, 0.1))
```
```{r}
#visualize the Highschool network by residentil area
coul  <- brewer.pal(length(unique(V(Highschool)$hall)), "Set2")
my_color <- coul[as.numeric(as.factor(V(Highschool)$hall))]
set.seed(10)
plot(Highschool, vertex.color = my_color,
     vertex.size=5,
     layout=layout.fruchterman.reingold(Highschool),vertex.label=NA,
     main="Highschool network by Hall")
#add the legend of the color of the nodes at the top left corner
legend("bottomleft", legend=levels(as.factor(V(Highschool)$gender)) ,col = coul , bty = "n", pch=20 , pt.cex = 1.5, cex = 1.5, horiz = FALSE, inset = c(0.1, 0.1))
```
```{r}
#introduce subgraph by gender = F, calculate their edge densities
group_female <- as.factor(unique(V(Highschool)$gender=='female'))
sapply(levels(group_female), function(x) {
  y <- induced_subgraph(Highschool, which(V(Highschool)$gender==x))
  paste0("Density for ", x, " friends is ", edge_density(y))
})



```
```{r}
group <- as.factor(unique(V(Highschool)$hall))
sapply(levels(group), function(x) {
  y <- induced_subgraph(Highschool, which(V(Highschool)$hall==x))
  paste0("Density for ", x, " friends is ", edge_density(y))
})
```
```{r}
#introduce subgraph by gender, calculate their edge densities
group <- as.factor(unique(V(Highschool)$gender))
sapply(levels(group), function(x) {
  y <- induced_subgraph(Highschool, which(V(Highschool)$gender==x))
  paste0("Density for ", x, " friends is ", edge_density(y))
})

```
Question 5 (4 points):
1)	Calculate the modularity of the Highschool network if community is merely identified by a) gender and b) residential hall, respectively.
2)	Search the Louvain Community Detection and explain the algorithm in your own words.
3)	Use the Louvain Community Detection to identify communities in the Highschool network. Compare the modularity value produced by the Louvain algorithm to those in 1), and explain the reasons for the differences.
```{r}
### customize community by gender

genderCommunity<-V(Highschool)$gender
genderCommunity<-replace(genderCommunity,genderCommunity=="female",1)
genderCommunity<-replace(genderCommunity,genderCommunity=="male",2)
genderCommunity<-replace(genderCommunity,genderCommunity=="unknown",3)
genderCommunity<-as.numeric(genderCommunity)

gender.clustering <- make_clusters(Highschool, membership=genderCommunity)
modularity(gender.clustering)

```
```{r}
### customize community by hall
hallCommunity<-V(Highschool)$hall
hallCommunity<-replace(hallCommunity,hallCommunity=="1501",1)
hallCommunity<-replace(hallCommunity,hallCommunity=="1502",2)
hallCommunity<-replace(hallCommunity,hallCommunity=="1503",3)
hallCommunity<-replace(hallCommunity,hallCommunity=="1504",4)
hallCommunity<-replace(hallCommunity,hallCommunity=="1505",5)
hallCommunity<-as.numeric(hallCommunity)

hall.clustering <- make_clusters(Highschool, membership=hallCommunity)
modularity(hall.clustering)

```
```{r}
### Louvain algorithm ###
Louv<-cluster_louvain(Highschool)
modularity(Louv)

```
```{r}
### Louvain algorithm ###
Louv<-cluster_louvain(Facebook)
modularity(Louv)
```
Exercise two: Network formation models
Network relationships come in many shapes and sizes, and so there is no single model which encompasses them all.
But over time, people do summarize some common paradigm that can be used to build a synthetic network.
In the lecture, we mentioned three major architectures to build a synthetic network, which is Erdos-Renyi Random Graph Model,
Small-world Random Graph Model, and Barabasi-Albert (BA) model.


```{r}
sample_gnp(20, 0.1, directed = FALSE, loops = FALSE)
#visualize the network
plot(sample_gnp(20, 0.1, directed = FALSE, loops = FALSE),vertex.label=NA)
#add the name of the plot
title(main="ER1")
```
```{r}
ER1 <-sample_gnp(20, 0.1, directed = FALSE, loops = FALSE)
plot((ER1), vertex.label=NA)
#add the name of the plot
title(main="ER1")
```
```{r}

ER2 <- sample_gnp(20, 0.2, directed = FALSE, loops = FALSE)
plot((ER2),vertex.label=NA)
#add the name of the plot
title(main="ER2")
```
```{r}
ER3 <-sample_gnp(20, 0.3, directed = FALSE, loops = FALSE)
plot((ER2),vertex.label=NA)
#add the name of the plot
title(main="ER3")
```
```{r}
#average degree of the ER1
mean(degree(ER1))
```
```{r}
mean(degree(ER2))
```
```{r}
mean(degree(ER3))
```
```{r}
#minimum degree of the ER1
min(degree(ER1))
```
```{r}
min(degree(ER2))
```
```{r}
min(degree(ER3))
```
```{r}
#maximum degree of the ER1
max(degree(ER1))
```
```{r}
max(degree(ER2))
```
```{r}
max(degree(ER3))
```
```{r}
ER1000 <-sample_gnp(1000, 0.1, directed = FALSE, loops = FALSE)
plot((ER1000), vertex.label=NA)
#add the name of the plot
title(main="ER1000")

```
```{r}
transitivity(ER1000)
```
```{r}
ER1000_2 <-sample_gnp(1000, 0.2, directed = FALSE, loops = FALSE)
ER1000_3 <-sample_gnp(1000, 0.3, directed = FALSE, loops = FALSE)
ER1000_4 <-sample_gnp(1000, 0.4, directed = FALSE, loops = FALSE)
ER1000_5 <-sample_gnp(1000, 0.5, directed = FALSE, loops = FALSE)
ER1000_9 <-sample_gnp(1000, 0.9, directed = FALSE, loops = FALSE)
# plot((ER1000_2), vertex.label=NA)
#add the name of the plot
# title(main="ER1000_2")

```
```{r}
# transitivity(ER1000_2)
transitivity(ER1000_9)
```
```{r}
Regular<-watts.strogatz.game(dim=1,size=300,nei=6, p=0)
plot(Regular, layout=layout.circle, vertex.label=NA, vertex.size=5, main= "Network with zero rewiring probability ")
SW1<-watts.strogatz.game(dim=1,size=300,nei=6, p=0.001)
plot(SW1, layout=layout.circle, vertex.label=NA, vertex.size=5, main= "Network with 0.001 rewiring probability ")
SW2<-watts.strogatz.game(dim=1,size=300,nei=6, p=0.01)
plot(SW2, layout=layout.circle, vertex.label=NA, vertex.size=5, main= "Network with 0.01 rewiring probability ")
SW3<-watts.strogatz.game(dim=1,size=300,nei=6, p=0.1)
plot(SW3, layout=layout.circle, vertex.label=NA, vertex.size=5, main= "Network with 0.1 rewiring probability ")

```
```{r}
transitivity(Regular)
```
```{r}
transitivity(SW1)
```
```{r}
transitivity(SW2)
```
```{r}
transitivity(SW3)
```
```{r}
#calculate teh averahe path length
mean_distance(Regular)
```
```{r}
mean_distance(SW1)
```
```{r}
mean_distance(SW2)
```
```{r}
mean_distance(SW3)

```
```{r}
Regular8<-watts.strogatz.game(dim=1,size=300,nei=6, p=0)
plot(Regular8, layout=layout.circle, vertex.label=NA, vertex.size=5, main= "Network with zero rewiring probability ")
```
```{r}
#make the previos plot in y range from 0 to 1
p<-seq(0,1,0.01)
mean_distance<-c()
clustering<-c()
for (i in p){
  Regular8<-watts.strogatz.game(dim=1,size=300,nei=6, p=i)
  mean_distance<-c(mean_distance,mean_distance(Regular8))
  clustering<-c(clustering,transitivity(Regular8))
}
par(mfrow = c(1, 2))

plot(p,mean_distance,xlab="Rewiring probability",ylab="Average path length",ylim=c(0,1))
plot(p,clustering,col="red", xlab="Rewiring probability",ylab="Clustering",ylim=c(0,1))
legend("topright",c("Average path length","Clustering coefficient"),col=c("black","red"),lty=1)

```
```{r}
g0 <- barabasi.game(100, power =  0.1, m = NULL, out.dist = NULL, out.seq = NULL, out.pref = FALSE, zero.appeal = 1, directed = FALSE,algorithm ="psumtree", start.graph = NULL)
plot(g0, vertex.label= NA, edge.arrow.size=0.02,vertex.size =5, main = "Scale-free network model, power=1")


```

Exercise three: Simulation of simple and complex contagion
In this exercise, you will simulate the spread of simple and complex contagion in the Highschool network.

For the Highschool network, identify five edges which after deletion, there will be significant gain of the average path lengths of the network.
In other words, if such five edges did not exist, the average path length of the network would increase significant.
Provide your answer in the format of A-B, in which A and B are the node ID. Are they weak ties or strong ties? (Question 10, 2 points)
```{r}
#calculate 5 edges with the highest betweenness centrality in Highschool network
edge_betweenness <- edge_betweenness(Highschool)
top_5_edges <- sort(edge_betweenness, decreasing = TRUE)[1:5]
top_5_edges_indices <- which(edge_betweenness %in% top_5_edges)
top_5_edges <- as_edgelist(Highschool)[top_5_edges_indices,]
top_5_edges
```
```{r}
stopifnot(require(data.table))
stopifnot(require(Matrix))

calculate_value <- function(node, each_neighbors,Pprob){
  return(each_neighbors[[node]][ which(runif(length(each_neighbors[[node]]), 0, 1)<=Pprob)])
  #'runif' is a function to generate random number in R
}
#This function:
#1) searches the neighbors of contagious node;
#2) To those who are connected to a contagious node, generates a random number and compare to the
#probability of p, if random number<p, this node will be infected and return the value of 1

IC<-function(node_seed,network,Pprob){

  #prepare input for the 'calculate_value' function#
  adj_matrix <- igraph::as_adjacency_matrix(network, type = 'both')
  each_neighbors <- which(adj_matrix > 0, arr.ind = TRUE)
  each_neighbors <- split(each_neighbors[, 2], each_neighbors[, 1]) #get the neigbhour list of each node

  nNode<-vcount(network)
  node_status <- rep.int(0, nNode) #start from a healthy population
  day_infected<-vector()#Total number of infected population
  new_infected <- list()  # Record the ID of person getting infected at each time step

  day<-1
  node_status[as.numeric(node_seed)] <- 1 # infected(value=1) health(value=0)
  day_infected[day] <- sum(node_status )
  new_infected[[day]]<-node_seed #The ID of the person infected in Day 1 (Patient Zero)

  #simulate the spread of virus within 4 weeks##
  for (day in c(2:28)){
    ContagiousID<-which(node_status == 1)
    infectedID<-unlist(lapply(ContagiousID,calculate_value,each_neighbors,Pprob))
    newinfectedID<- setdiff(infectedID, which(node_status == 1))

    #Update the node status and other variables
    node_status[newinfectedID] <- 1
    day_infected[day] <- length(newinfectedID)
    new_infected[[day]]<-newinfectedID

    day=day+1
  }
  return(day_infected)  #return the number of newly infected people by day
  #return(list(day_infected,new_infected)) #if you want to see the ID of infected ppl in each day, use this command instead
}

```
```{r}
# IC(5, Highschool, 0.15)

# run the IC model 100 times and take the average
IC_average <- function(node_seed,network,Pprob){
  n <- 100
  result <- matrix(0, nrow = 28, ncol = n)
  for (i in 1:n){
    result[, i] <- IC(node_seed,network,Pprob)
  }
  return(apply(result, 1, mean))
}


```
```{r}
IC_average(5, Highschool, 0.15)


```
```{r}
#delete the the nodes with the highest betweenness centrality
Highschool2 <- delete_vertices(Highschool, top_5_edges)
```
```{r}
#delete the edhe between 5 and 6 and 5 and 7
Highschool3 <- delete_edges(Highschool, c(60, 44, 12, 24, 96, 94, 43, 90,46,58))
```


```{r}
IC_average(5, Highschool2, 0.15)
```
```{r}
IC_average(5, Highschool3, 0.15)
```
```{r}
#make a plot of the average number of infected people by day for Highschool, Highschool2, and Highschool3
#add color to the lines to distinguish the three networks
plot(IC_average(5, Highschool, 0.15), type = "l", col = "red", ylim = c(0, 10), xlab = "Day", ylab = "Average number of infected people")
lines(IC_average(5, Highschool2, 0.15), type = "l", col = "blue")
lines(IC_average(5, Highschool3, 0.15), type = "l", col = "green")
legend("topright", c("Highschool", "Highschool2", "Highschool3"), col = c("red", "blue", "green"), lty = 1)

```
```{r}
plot(IC_average(5, Highschool, 0.8), type = "l", col = "red", ylim = c(0, 36), xlab = "Day", ylab = "Average number of infected people")
lines(IC_average(5, Highschool2, 0.8), type = "l", col = "blue")
lines(IC_average(5, Highschool3, 0.8), type = "l", col = "green")
legend("topright", c("Highschool", "Highschool2", "Highschool3"), col = c("red", "blue", "green"), lty = 1)
```

```



```
```
