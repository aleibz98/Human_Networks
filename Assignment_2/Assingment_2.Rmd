---
title: "Assingment_2"
output: html_document
date: "2023-03-15"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# libraries
library(igraph)
library(RColorBrewer)
library(visNetwork)
```

```{r}
highschool_edge<-read.csv("Assignment_2/data/Highschool_network_edge.csv")
highschool_att <- read.csv("Assignment_2/data/Highschool_network_att.csv")
facebook_att <- read.csv("Assignment_2/data/Facebook_network_att.csv")
facebook_edge <- read.csv("Assignment_2/data/Facebook_network_edge.csv")
```

```{r}
highschool_nodes<-data.frame(name=as.character(highschool_att$NodeID),
                             gender=as.character(highschool_att$Gender),
                             hall=as.character(highschool_att$Hall))

highschool_edges<-data.frame(from=c(as.character(highschool_edge[,1])),
                             to=c(as.character(highschool_edge[,2])))

Highschool<-graph_from_data_frame(highschool_edges,directed = FALSE,vertices = highschool_nodes)

co <- components(Highschool)

Highschool <- induced.subgraph(Highschool, which(co$membership == which.max(co$csize))) #use only the largest component for analysis
summary(Highschool)
```

```{r}
#build facebook network 
facebook_nodes<-data.frame(name=as.character(facebook_att$NodeID))

facebook_edges<-data.frame(from=c(as.character(facebook_edge[,1])),
                           to=c(as.character(facebook_edge[,2])))

Facebook<-graph_from_data_frame(facebook_edges,directed = FALSE,vertices = facebook_nodes)

summary(Facebook)
```

## Node-level Centrality Measures

Question 1 (3 points):

• Find out the node ID of 
  a) highest degree 
  b) highest betweenness 
  c) highest closeness
  d) highest eigenvector in the Highschool network;

• Highlight the above nodes in the Highschool network;

• Explain why these metrics identify the same node or different nodes as the most
central one.

```{r}
# Get the node with the highest degree
which.max(degree(Highschool, mode = "all"))

# Get the node with the highest betweenness
which.max(betweenness(Highschool, directed = FALSE, normalized = TRUE))

# Get the node with the highest closeness
which.max(closeness(Highschool, normalized = TRUE))

# Get the node with the highest eigenvector
which.max(as.numeric(unlist(eigen_centrality(Highschool))))
```

```{r}
#function to visualize the network (with interaction) 
set.seed(100)
Highschool_interactive_layout<- visNetwork(data.frame(id=V(Highschool)$name),
                                           highschool_edges, main = "Highschool",
                                           submain="Can zoom in/out to check the IDs and ties") %>%
  visIgraphLayout(layout = "layout_nicely",smooth = FALSE) %>% visNodes(shape="circle",label = TRUE) %>%
  visOptions(highlightNearest = list(enabled = T, hover = T), nodesIdSelection = T)

Highschool_interactive_layout
```


Question 2 (5 points):

• Study the correlations between 
  a) degree and betweenness
  b) degree and closeness
  c) degree and eigenvector for all the nodes in the Highschool network;

• Study the correlations between 
  a) degree and betweenness
  b) degree and closeness
  c) degree and eigenvector for all the nodes in the Facebook network;

• From the above results, how well do different metrics correlate with each other? Which centrality metric will you use and why?


```{r}
# For Highschool network
# Correlation between degree and betweenness
cor.test(degree(Highschool, mode = "all"), betweenness(Highschool, directed = FALSE, normalized = TRUE))

# Correlation between degree and closeness
cor.test(degree(Highschool, mode = "all"), closeness(Highschool, normalized = TRUE))

# Correlation between degree and eigenvector
cor.test(degree(Highschool, mode = "all"), as.numeric(unlist(eigen_centrality(Highschool)))) # Error - must be same length
```

```{r}
# For Facebook network
# Correlation between degree and betweenness
cor.test(degree(Facebook, mode = "all"), betweenness(Facebook, directed = FALSE, normalized = TRUE))

# Correlation between degree and closeness
cor.test(degree(Facebook, mode = "all"), closeness(Facebook, normalized = TRUE))

# Correlation between degree and eigenvector
cor.test(degree(Facebook, mode = "all"), as.numeric(unlist(eigen_centrality(Facebook)))) # Error - must be same length
```

# TODO: Some correlation plots


Question 3 (5 points):

• For both the Highschool and Facebook networks, calculate the shortest path lengths between every pair of two nodes. 
  How many percentage of nodes can be reached within 6 path lengths? 
  Does “six degree of separation” apply to each network?

• Study the degree distribution of these two networks, are they similar? 
  Then use degree distribution to explain the degree of separation you answered above.


```{r}
#Shortest path lengths between every pair of two nodes in the network
hs_distances <- distances(Highschool,
                          v = V(Highschool),
                          to = V(Highschool),
                          mode = c("all", "out", "in"),
                          weights = NULL)

fb_distances <- distances(Facebook,
                          v = V(Facebook),
                          to = V(Facebook),
                          mode = c("all", "out", "in"),
                          weights = NULL)
```

```{r}
# What's the percentage of nodes that can be reached within 6 path lengths?
# Highschool
sum(hs_distances <= 6) / length(hs_distances)
# 0.9857565

# Facebook
sum(fb_distances <= 6) / length(fb_distances)
# 0.9797049

# Does "six degree of separation" apply to each network?
# Yes, it does. The percentage of nodes that can be reached within 6 path lengths is very close to 1.
```

```{r}
# Use an histogram to study the degree distribution of these two networks
# Highschool
par(mfrow=c(1,2))
hist(degree(Highschool, mode = "all"), main = "Highschool Degree Distribution", xlab = "Degree", ylab = "Frequency")

# Facebook
hist(degree(Facebook, mode = "all"), main = "Facebook Degree Distribution", xlab = "Degree", ylab = "Frequency", breaks=50)
```

```{r}
# TODO: Explain the degree of separation given degree distribution
```
Question 4:
  1) Visualize the network and color the nodes by gender and residential hall, respectively. #DONE
  
  2) Build 8 subgraphs of the original network according to gender and residential hall: 
      1 subgraph for female student, 
      1 subgraph for male student, 
      1 subgraph for students with unknown gender, 
      and 5 subgraphs for students living in residential hall from 1501 to 1505, respectively. #DONE - Too easy(?)

      For example, to build a subgraph of all female students, you should keep all the nodes of female students and the edges between them. Other nodes and edges are removed.

  3) Study the edge density of all the subgraph and compare them to the edge density of the original network. 
      What is your conclusion for the hypothesis?


```{r}
## visualize the network by gender
par(mfrow=c(1,2))
coul <- brewer.pal(length(unique( V(Highschool)$gender)), "Set2")
my_color <- coul[as.numeric(as.factor(V(Highschool)$gender))] 
set.seed(10)

plot(Highschool,
      vertex.color = my_color,
      vertex.size=5,
      layout=layout.fruchterman.reingold(Highschool),
      vertex.label=NA,
      main="Highschool network by gender")

legend("bottomleft", 
        legend=levels(as.factor(V(Highschool)$gender)),
        col = coul, bty = "n", pch=20 , pt.cex = 1.5, cex = 1.5, horiz = FALSE, inset = c(0.1, 0.1))
```

```{r}
## visualize the network by residential hall
coul <- brewer.pal(length(unique( V(Highschool)$hall)), "Set2")
my_color <- coul[as.numeric(as.factor(V(Highschool)$hall))] 
set.seed(10)

plot(Highschool,
      vertex.color = my_color,
      vertex.size=5,
      layout=layout.fruchterman.reingold(Highschool),
      vertex.label=NA,
      main="Highschool network by hall")

legend("bottomleft", 
        legend=levels(as.factor(V(Highschool)$hall)),
        col = coul, bty = "n", pch=20 , pt.cex = 1.5, cex = 1.5, horiz = FALSE, inset = c(0.1, 0.1))
```


```{r}
#introduce subgraph by gender, calculate their edge densities 
group <- as.factor(unique(V(Highschool)$gender))
sapply(levels(group), function(x) {
  y <- induced_subgraph(Highschool, which(V(Highschool)$gender==x))
  paste0("Density for ", x, " friends is ", edge_density(y))
  })


#introduce subgraph by hall, calculate their densities
group <- as.factor(unique(V(Highschool)$hall))
sapply(levels(group), function(x) {
  y <- induced_subgraph(Highschool, which(V(Highschool)$hall==x))
  paste0("Density for ", x, " friends is ", edge_density(y))
  })
```


```{r}
# TODO: Compare the densities to the density of the original network


```

Question 5 (4 points):

  1) Calculate the modularity of the Highschool network if community is merely identified by 
      a) gender and 
      b) residential hall, respectively.

  2) Search the Louvain Community Detection and explain the algorithm in your own words.

  3) Use the Louvain Community Detection to identify communities in the Highschool network. 
    Compare the modularity value produced by the Louvain algorithm to those in 1), and explain the reasons for the differences.


```{r}
### customize community by gender
genderCommunity <- V(Highschool)$gender
genderCommunity <- replace(genderCommunity, genderCommunity == "female", 1)
genderCommunity <- replace(genderCommunity, genderCommunity == "male", 2)
genderCommunity <- replace(genderCommunity, genderCommunity == "unknown", 3)
genderCommunity <- as.numeric(genderCommunity)
gender.clustering <- make_clusters(Highschool, membership=genderCommunity)
modularity(gender.clustering)
```

```{r}
### customize community by gender
hallCommunity <- V(Highschool)$hall
hallCommunity <- as.numeric(genderCommunity)
hall.clustering <- make_clusters(Highschool, membership = hallCommunity)
modularity(hall.clustering)
```

#TODO: Same result, so there must be something wrong... 


```{r}
Louv <- cluster_louvain(Highschool) 
modularity(Louv)
```

# TODO: 0.70 -> Too much difference

```{r}

```

```{r}

```

```{r}

```

```{r}

```
